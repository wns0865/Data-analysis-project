import pandas as pd
import numpy as np
import json
import os
# JSON 파일 경로
file_paths = ["data/files/", "data/files 1/"]

# 빈 데이터프레임 생성
PlayerInfo = pd.DataFrame([])

# 데이터 불러오기
for file_path in file_paths:
    file_list = os.listdir(file_path)

    for j in file_list:
        data_name = file_path.split('/')[-2]  # 파일 경로에서 디렉토리 이름 추출

        # JSON 파일 열기
        with open(file_path + f'{j}', 'r', encoding='utf-8') as file:
            json_data = json.load(file)
        
        data = pd.DataFrame([json_data])
        
        # JSON 데이터를 데이터프레임으로 변환
        PlayerInfo = pd.concat([PlayerInfo, data])

###### 쓸모없는 열 제거 (index, 생년월일, minSpeed)
PlayerInfo = PlayerInfo.drop(['index', 'birth', 'minSpeed'], axis=1)

# 'age' 열을 추출하여 제거
age_column = PlayerInfo.pop('age')

# 'age' 열을 2번째 열로 삽입
PlayerInfo.insert(1, 'age', age_column)

# 이름 순으로 정렬
PlayerInfo = PlayerInfo.sort_values('name')
PlayerInfo = PlayerInfo.reset_index(drop=True)
PlayerInfo

ARS_data = pd.read_excel('ARS 검사결과.xlsx')
ARS_data = ARS_data.sort_values('name')
ARS_data = ARS_data.reset_index(drop=True)
ARS_data

# ARS 검사와 게임 데이터 결합
data = pd.concat([ARS_data.iloc[:, :1], ARS_data.iloc[:, -3:], PlayerInfo.iloc[:, 1:]], axis=1)
data = data.reset_index(drop=True)
pd.set_option('display.max_rows', None)
# col 생략 없이 출력
pd.set_option('display.max_columns', None)
data['avg'] = data['score'] / data['playtime']
data

import matplotlib.pyplot as plt

# 변수에 대한 박스플롯
plt.figure(figsize=(12, 15))
variables = data.columns[6:]

for i, var in enumerate(variables):
    plt.subplot(4, 5, i+1)
    plt.boxplot(data[var])
    plt.title(var)

plt.tight_layout()
plt.show()


import seaborn as sns

# 상관 관계 분석
correlation = data.corr(numeric_only=True)

# 삼각형 마스크 생성
mask = np.triu(np.ones_like(correlation, dtype=bool))

plt.figure(figsize=(15, 12))
sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt=".2f", mask=mask)
plt.title('Correlation Heatmap')
plt.show()

# 히스토그램 그리기
plt.scatter(data['Total_score'], data['avg'])
plt.xlabel('Total_Score')
plt.ylabel('avg')
plt.show()

import statsmodels.api as sm

# 종속 변수와 독립 변수 설정
X = data.iloc[:, 4:]
y = data['Total_score']

# 단계적 선택을 위한 함수 정의
def stepwise_selection(X, y,
                       initial_list=[],
                       threshold_in=0.05,
                       threshold_out=0.05,
                       verbose=True):
    included = list(initial_list)
    while True:
        changed = False
        # 추가할 변수 후보 리스트 생성
        excluded = list(set(X.columns) - set(included))
        new_pval = pd.Series(index=excluded, dtype=np.float64)
        for new_column in excluded:
            # 새로운 변수를 기존 변수에 추가하여 회귀 모델 피팅
            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()
            new_pval[new_column] = model.pvalues[new_column]
        # 가장 유의한 p-value를 가진 변수 선택
        best_pval = new_pval.min()
        if best_pval < threshold_in:
            best_feature = new_pval.idxmin()
            included.append(best_feature)
            changed = True
            if verbose:
                print('변수 추가: {:30}  p-value: {:.3f}'.format(best_feature, best_pval))

        # 제거할 변수 후보 리스트 생성
        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()
        # 제거할 변수 후보 중 가장 높은 p-value를 가진 변수 선택
        pvalues = model.pvalues.iloc[1:]
        worst_pval = pvalues.max()
        if worst_pval >= threshold_out:
            worst_feature = pvalues.idxmax()
            included.remove(worst_feature)
            changed = True
            if verbose:
                print('변수 제거: {:30}  p-value: {:.3f}'.format(worst_feature, worst_pval))
        if not changed:
            break
    return included

# 단계적 선택 실행
selected_variables = stepwise_selection(X, y)

print("\n 최종 선택된 변수:")
print(selected_variables)

# 데이터 셋 분할 (Train 80% : Test 20%)
from sklearn.model_selection import train_test_split

# 전체 변수 선택
X_data = data.iloc[:, 4:].values

# 변수선택법에 의해 선택된 변수
# X_data = data.loc[:, selected_variables]
y_data = data['Total_score']

X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=0)

# 분할된 데이터셋 확인
print("Train set shapes: X =", X_train.shape, " y =", y_train.shape)
print("Test set shapes: X =", X_test.shape, " y =", y_test.shape)

# 회귀분석을 이용한 예측
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(X_train, y_train)

# 모델 결과 확인 (평가 지표 : MAE, MSE, R2_score)
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

lr_pred = lr.predict(X_test)

mae = mean_absolute_error(y_test, lr_pred)
mse = mean_squared_error(y_test, lr_pred)
r2_score = r2_score(y_test, lr_pred)

print("MAE: {:.3f}".format(mae))
print("MSE: {:.3f}".format(mse))
print("R2_score: {:.3f}%".format(r2_score*100))

from sklearn.ensemble import RandomForestRegressor
ran = RandomForestRegressor(random_state=0)
ran.fit(X_train, y_train)

# 모델 결과 확인 (평가 지표 : MAE, MSE, R2_score)
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

ran_pred = ran.predict(X_test)

mae = mean_absolute_error(y_test, ran_pred)
mse = mean_squared_error(y_test, ran_pred)
r2_score = r2_score(y_test, ran_pred)

print("MAE: {:.3f}".format(mae))
print("MSE: {:.3f}".format(mse))
print("R2_score: {:.3f}%".format(r2_score*100))

# 결과 시각화
# 추론이 진행된 날짜만 시각화(7일)
plt.figure(figsize=(9, 6))
plt.ylim(0, 30)
plt.xticks(np.arange(0, len(y_test), 1))
plt.yticks(np.arange(0, 31, 2))

plt.grid(True)
plt.autoscale(axis='x', tight=True)

plt.plot(range(len(y_test)), y_test, color = 'black', alpha = 0.8, label = 'actual value', marker = '.')
plt.plot(range(len(y_test)), lr_pred, color = 'r', alpha = 0.8, label = 'LinearRegression', marker = '.')
plt.plot(range(len(y_test)), ran_pred, color = 'b', alpha = 0.8, label = 'RandomForest', marker = '.')

plt.legend(loc='center left', bbox_to_anchor=(0.75, 1.09))

# 데이터 셋 분할 (Train 80% : Test 20%)
from sklearn.model_selection import train_test_split

# 전체 변수 선택
X_data = data.iloc[:, 4:]
y_data = data['Total_score']

X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=0)

# 분할된 데이터셋 확인
print("Train set shapes: X =", X_train.shape, " y =", y_train.shape)
print("Test set shapes: X =", X_test.shape, " y =", y_test.shape)

#랜덤포레스트
ran = RandomForestRegressor(random_state=0)
ran.fit(X_train, y_train)

# 랜덤 포레스트 변수 중요도
feature_importance = pd.DataFrame({
    'feature': X_data.columns,
    'importance': ran.feature_importances_
})

feature_importance = feature_importance.sort_values('importance', ascending = False)
feature_importance = feature_importance.reset_index(drop=True)

# 변수 중요도 시각화
import plotly.express as px

# 중요도별 순서 확인하기.
fig = px.bar(feature_importance, x='feature', y='importance')
fig.show()
feature_importance

# 데이터 셋 분할 (Train 80% : Test 20%)
from sklearn.model_selection import train_test_split

# 전체 변수 선택
X_data = data.loc[:, feature_importance['feature'][:5]]
y_data = data['Total_score']

X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=0)

# 분할된 데이터셋 확인
print("Train set shapes: X =", X_train.shape, " y =", y_train.shape)
print("Test set shapes: X =", X_test.shape, " y =", y_test.shape)

# 회귀분석을 이용한 예측
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(X_train, y_train)

# 모델 결과 확인 (평가 지표 : MAE, MSE, R2_score)
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

lr_pred = lr.predict(X_test)

mae = mean_absolute_error(y_test, lr_pred)
mse = mean_squared_error(y_test, lr_pred)
r2_score = r2_score(y_test, lr_pred)

print("MAE: {:.3f}".format(mae))
print("MSE: {:.3f}".format(mse))
print("R2_score: {:.3f}%".format(r2_score*100))

ran = RandomForestRegressor(random_state=0)
ran.fit(X_train, y_train)

# 모델 결과 확인 (평가 지표 : MAE, MSE, R2_score)
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

ran_pred = ran.predict(X_test)

mae = mean_absolute_error(y_test, ran_pred)
mse = mean_squared_error(y_test, ran_pred)
r2_score = r2_score(y_test, ran_pred)

print("MAE: {:.3f}".format(mae))
print("MSE: {:.3f}".format(mse))
print("R2_score: {:.3f}%".format(r2_score*100))

# 결과 시각화
# 추론이 진행된 날짜만 시각화(7일)
plt.figure(figsize=(9, 6))
plt.ylim(0, 30)
plt.xticks(np.arange(0, len(y_test), 1))
plt.yticks(np.arange(0, 31, 2))

plt.grid(True)
plt.autoscale(axis='x', tight=True)

plt.plot(range(len(y_test)), y_test, color = 'black', alpha = 0.8, label = 'actual value', marker = '.')
plt.plot(range(len(y_test)), lr_pred, color = 'r', alpha = 0.8, label = 'LinearRegression', marker = '.')
plt.plot(range(len(y_test)), ran_pred, color = 'b', alpha = 0.8, label = 'RandomForest', marker = '.')

plt.legend(loc='center left', bbox_to_anchor=(0.75, 1.09))